{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bFbJwgiLEOd5"
      },
      "outputs": [],
      "source": [
        "import time as tm\n",
        "# import predict\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qMxt6nMeEUNH"
      },
      "outputs": [],
      "source": [
        "def extract_background_color(image):\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    tl = image[0, 0]\n",
        "    tr = image[0, width - 1]\n",
        "    bl = image[height - 1, 0]\n",
        "    br = image[height - 1, width - 1]\n",
        "\n",
        "    if (np.array_equal(tl, tr)) and (np.array_equal(tl, bl)) and (np.array_equal(tl, br)):\n",
        "        return tl\n",
        "    elif ( ((np.array_equal(tl, tr)) and (np.array_equal(tl, bl))) or ((np.array_equal(tl, bl)) and (np.array_equal(tl, br))) or ((np.array_equal(tl, tr)) and (np.array_equal(tl, br))) ):\n",
        "        return tl\n",
        "    elif ( ((np.array_equal(tr, tl)) and (np.array_equal(tr, bl))) or ((np.array_equal(tr, bl)) and (np.array_equal(tr, br))) or ((np.array_equal(tr, tl)) and (np.array_equal(tr, br))) ):\n",
        "        return tr\n",
        "    elif ( ((np.array_equal(bl, tr)) and (np.array_equal(bl, tl))) or ((np.array_equal(bl, tl)) and (np.array_equal(bl, br))) or ((np.array_equal(bl, tr)) and (np.array_equal(bl, br))) ):\n",
        "        return bl\n",
        "    elif ( ((np.array_equal(br, tl)) and (np.array_equal(br, bl))) or ((np.array_equal(br, bl)) and (np.array_equal(br, tr))) or ((np.array_equal(br, tl)) and (np.array_equal(br, tr))) ):\n",
        "        return br\n",
        "    elif (np.array_equal(tr, br) or np.array_equal(tr, bl) or np.array_equal(tr, tl)):\n",
        "        return tr\n",
        "    elif (np.array_equal(tl, br) or np.array_equal(tl, bl) or np.array_equal(tr, tl)):\n",
        "        return tl\n",
        "    elif (np.array_equal(br, tr) or np.array_equal(br, bl) or np.array_equal(br, tl)):\n",
        "        return br\n",
        "    else:\n",
        "        return bl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk8lpSCTj1Yt"
      },
      "outputs": [],
      "source": [
        "def trainDecaptcha(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    y_train = np.loadtxt(\"labels.txt\", dtype=str)\n",
        "    y_train = y_train[:len(filenames)]\n",
        "\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        # cv2_imshow(img)\n",
        "        img = img[:, 358:458]\n",
        "        # cv2_imshow(img)\n",
        "\n",
        "        hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "        indices = np.where((hsv_img == extract_background_color(hsv_img)).all(axis=2))\n",
        "        hsv_img[indices] = [255, 255, 255]\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        kernel1 = np.ones((3, 3), np.uint8)\n",
        "        dilate_img = cv2.dilate(hsv_img, kernel, iterations=1)\n",
        "        gray_img = cv2.cvtColor(dilate_img, cv2.COLOR_BGR2GRAY)\n",
        "        gray_img = cv2.fastNlMeansDenoising(gray_img, None, 20, 7, 21)\n",
        "        erod_img = cv2.erode(gray_img, kernel1, iterations=1)\n",
        "        _, otsu_img = cv2.threshold(erod_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        cv2_imshow(otsu_img)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    model = LogisticRegression(max_iter=100)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "train_size = 10\n",
        "train_file = [ \"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range( train_size ) ]\n",
        "model = trainDecaptcha(train_file)\n",
        "\n",
        "def decaptcha(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "        indices = np.where((hsv_img == extract_background_color(hsv_img)).all(axis=2))\n",
        "        hsv_img[indices] = [255, 255, 255]\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        kernel1 = np.ones((3, 3), np.uint8)\n",
        "        dilate_img = cv2.dilate(hsv_img, kernel, iterations=1)\n",
        "        gray_img = cv2.cvtColor(dilate_img, cv2.COLOR_BGR2GRAY)\n",
        "        gray_img = cv2.fastNlMeansDenoising(gray_img, None, 20, 7, 21)\n",
        "        erod_img = cv2.erode(gray_img, kernel1, iterations=1)\n",
        "        _, otsu_img = cv2.threshold(erod_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_pred = model.predict(X_train)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HaU4_6msRI9"
      },
      "outputs": [],
      "source": [
        "def rotate_img(file, angle):\n",
        "    tmp = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "    tmp = cv2.bitwise_not(tmp)\n",
        "    rot = cv2.getRotationMatrix2D((100 / 2, 100 / 2), angle, 1.0)\n",
        "    tmp = cv2.warpAffine(tmp, rot, (100, 100))\n",
        "    tmp = cv2.bitwise_not(tmp)\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oys2PrFdgYNA",
        "outputId": "d4fed1ea-7b74-4c1f-81e4-06d376cd452f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.005398607600000105\n",
            "['EVEN', 'EVEN', 'EVEN', 'EVEN', 'ODD', 'ODD', 'EVEN', 'ODD', 'ODD', 'EVEN']\n"
          ]
        }
      ],
      "source": [
        "import time as tm\n",
        "from PIL import Image\n",
        "import pickle\n",
        "\n",
        "def decaptcha2(filenames):\n",
        "    l = []\n",
        "    # ref_images = []\n",
        "    # tstfile = [\"/content/drive/MyDrive/Colab/reference/%d.png\" % i for i in {0,2,4,6,8,10,12,14}]\n",
        "    # for file in tstfile:\n",
        "    #     tmp = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "    #     ref_images.append(tmp)\n",
        "    #     for angle in {10,-10,20,-20,30,-30}:\n",
        "    #         ref_images.append(rotate_img(file,angle))\n",
        "    # tstfile = [\"/content/drive/MyDrive/Colab/reference/%d.png\" % i for i in {1,3,5,7,9,11,13,15}]\n",
        "    # for file in tstfile:\n",
        "    #     tmp = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "    #     ref_images.append(tmp)\n",
        "    #     for angle in {10,-10,20,-20,30,-30}:\n",
        "    #         ref_images.append(rotate_img(file,angle))\n",
        "    # with open('ref_images.pkl', 'wb') as file:\n",
        "    #     pickle.dump(ref_images, file)\n",
        "\n",
        "    with open('ref_images.pkl', 'rb') as file:\n",
        "        ref_images = pickle.load(file)\n",
        "\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = Image.open(file)  # Open the image\n",
        "        img = np.array(img)\n",
        "        # img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
        "        img = img[:, 358:458]\n",
        "        indices = np.where((img == extract_background_color(img)).all(axis=2))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        # _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        otsu_img = img\n",
        "        cropped_bottom = otsu_img[:5, :]\n",
        "        cropped_top = otsu_img[5:, :]\n",
        "        otsu_img = np.concatenate((cropped_top, cropped_bottom), axis=0)\n",
        "        # cv2_imshow(otsu_img)\n",
        "        ans = (900000, -1)\n",
        "        for j,image in enumerate(ref_images):\n",
        "            bitwise_xor = cv2.bitwise_xor(image, otsu_img)\n",
        "            tmpvar = cv2.sumElems(bitwise_xor)[0]\n",
        "            if(tmpvar<ans[0]):\n",
        "                ans = (tmpvar,j)\n",
        "        if(ans[1]>55):\n",
        "            l.append(\"ODD\")\n",
        "        else:\n",
        "            l.append(\"EVEN\")\n",
        "\n",
        "    return l\n",
        "\n",
        "\n",
        "tss = 1500\n",
        "tse = 1510\n",
        "train_file2 = [\"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range(tss,tse)]\n",
        "\n",
        "tic = tm.perf_counter()\n",
        "output = decaptcha2(train_file2)\n",
        "toc = tm.perf_counter()\n",
        "print((toc - tic) / (tse-tss))\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQOA1tcF5bla"
      },
      "outputs": [],
      "source": [
        "#################  METHOD 3  #################\n",
        "from joblib import dump, load\n",
        "import skimage.io as io\n",
        "\n",
        "def trainDecaptcha3(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    y_train = np.loadtxt(\"/content/drive/MyDrive/Colab/train/labels.txt\", dtype=str)\n",
        "    y_train = y_train[:len(filenames)]\n",
        "\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        indices = np.where((img == extract_background_color(img)).all(axis=2))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        # cropped_bottom = np.full((5, 100), 255, dtype=np.uint8)\n",
        "        # cropped_top = otsu_img[5:, :]\n",
        "        # otsu_img = np.concatenate((cropped_top, cropped_bottom), axis=0)\n",
        "        # cv2_imshow(otsu_img)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "\n",
        "    model = LogisticRegression(max_iter=100)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    dump(model, 'model.joblib')\n",
        "\n",
        "    return model\n",
        "\n",
        "train_size = 500\n",
        "train_file = [ \"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range( train_size ) ]\n",
        "model = trainDecaptcha3(train_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc_YmHEN7kW0",
        "outputId": "4bc55182-4e88-4d72-cc77-808d49295bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0041815361000044505\n",
            "['ODD' 'EVEN' 'EVEN' 'ODD' 'EVEN' 'EVEN' 'EVEN' 'ODD' 'EVEN' 'EVEN' 'ODD'\n",
            " 'ODD' 'ODD' 'ODD' 'ODD' 'EVEN' 'ODD' 'EVEN' 'EVEN' 'EVEN' 'EVEN' 'EVEN'\n",
            " 'ODD' 'EVEN' 'EVEN' 'EVEN' 'EVEN' 'ODD' 'ODD' 'EVEN' 'ODD' 'ODD' 'EVEN'\n",
            " 'EVEN' 'ODD' 'EVEN' 'ODD' 'EVEN' 'EVEN' 'ODD' 'ODD' 'ODD' 'ODD' 'ODD'\n",
            " 'ODD' 'ODD' 'ODD' 'EVEN' 'ODD' 'EVEN']\n"
          ]
        }
      ],
      "source": [
        "def decaptcha3(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        indices = np.where((img == extract_background_color(img)).all(axis=2))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "\n",
        "    # model = LogisticRegression()\n",
        "    model = load('model.joblib')\n",
        "    y_pred = model.predict(X_train)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "tss = 50\n",
        "tse = 100\n",
        "tff = [\"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range(tss,tse)]\n",
        "\n",
        "tic = tm.perf_counter()\n",
        "prediction = decaptcha3(tff)\n",
        "toc = tm.perf_counter()\n",
        "print((toc - tic) / (tse-tss))\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6o2GXPzHrTm",
        "outputId": "45fa843d-4590-4050-ec7b-dc221478b296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00614365772000383\n"
          ]
        }
      ],
      "source": [
        "#################  METHOD 4  #################\n",
        "import concurrent.futures\n",
        "\n",
        "def trainDecaptcha4(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    y_train = np.loadtxt(\"/content/drive/MyDrive/Colab/train/labels.txt\", dtype=str)\n",
        "    y_train = y_train[:len(filenames)]\n",
        "\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        indices = np.where((img == extract_background_color(img)).all(axis=2))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        # cropped_bottom = np.full((5, 100), 255, dtype=np.uint8)\n",
        "        # cropped_top = otsu_img[5:, :]\n",
        "        # otsu_img = np.concatenate((cropped_top, cropped_bottom), axis=0)\n",
        "        # cv2_imshow(otsu_img)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "    dump(knn, 'knn.joblib')\n",
        "    return knn\n",
        "\n",
        "train_size = 2000\n",
        "train_file = [ \"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range( train_size ) ]\n",
        "knn2 = trainDecaptcha4(train_file)\n",
        "\n",
        "def decaptcha4(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        indices = (img == extract_background_color(img)).all(axis=2)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        # cropped_bottom = np.full((5, 100), 255, dtype=np.uint8)\n",
        "        # cropped_top = otsu_img[5:, :]\n",
        "        # otsu_img = np.concatenate((cropped_top, cropped_bottom), axis=0)\n",
        "\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "\n",
        "    knn = load('knn.joblib')\n",
        "    y_pred = knn.predict(X_train)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "tss = 0\n",
        "tse = 100\n",
        "tff = [\"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range(tss,tse)]\n",
        "\n",
        "tic = tm.perf_counter()\n",
        "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "#     prediction = executor.map(decaptcha3, tff)\n",
        "prediction = decaptcha3(tff)\n",
        "toc = tm.perf_counter()\n",
        "print((toc - tic) / (tse-tss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j9_ynfljoTD",
        "outputId": "20688c06-a1ed-4f71-aa04-0eac7a9813a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.004304970659995888\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def trainDecaptcha5(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    y_train = np.loadtxt(\"/content/drive/MyDrive/Colab/train/labels.txt\", dtype=str)\n",
        "    y_train = y_train[:len(filenames)]\n",
        "    y_train = np.where(y_train == \"EVEN\", 0, 1)\n",
        "\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        indices = (img == extract_background_color(img)).all(axis=2)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    dump(model, 'linearmodel.joblib')\n",
        "    return model\n",
        "\n",
        "train_size = 2000\n",
        "train_file = [ \"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range( train_size ) ]\n",
        "linerr = trainDecaptcha5(train_file)\n",
        "\n",
        "def decaptcha5(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        indices = (img == extract_background_color(img)).all(axis=2)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "    linearmodel = load('linearmodel.joblib')\n",
        "    y_pred = linearmodel.predict(X_train)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "tss = 0\n",
        "tse = 100\n",
        "tff = [\"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range(tss,tse)]\n",
        "\n",
        "tic = tm.perf_counter()\n",
        "prediction = decaptcha5(tff)\n",
        "toc = tm.perf_counter()\n",
        "print((toc - tic) / (tse-tss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oHMVR2yx2SYf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "def trainDecaptcha3(filenames):\n",
        "    X_train = np.zeros((len(filenames), 100 * 100))\n",
        "    y_train = np.loadtxt(\"/content/drive/MyDrive/Colab/train/labels.txt\", dtype=str)\n",
        "    y_train = y_train[:len(filenames)]\n",
        "\n",
        "    for i, file in enumerate(filenames):\n",
        "        img = cv2.imread(file)\n",
        "        img = img[:, 358:458]\n",
        "        indices = np.where((img == extract_background_color(img)).all(axis=2))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img[indices] = [255]\n",
        "        _, otsu_img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "        otsu = otsu_img / 255.\n",
        "        otsu = np.array(otsu)\n",
        "        otsu = otsu.flatten()\n",
        "        X_train[i] = otsu\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation = 'relu', input_shape = (100, 100)),\n",
        "        MaxPooling2D((2,2)),\n",
        "\n",
        "        Conv2D(32, (3,3), activation = 'relu'),\n",
        "        MaxPooling2D((2,2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(64, activation = 'relu'),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs = 5, batch_size = 64)\n",
        "\n",
        "\n",
        "    # model = LogisticRegression()\n",
        "    # model.train(X_train, y_train)\n",
        "\n",
        "    # Save the model to a file\n",
        "    # with open('model.pkl', 'wb') as file:\n",
        "    #     pickle.dump(model, file)\n",
        "    return model\n",
        "\n",
        "train_size = 200\n",
        "train_file = [ \"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range( train_size ) ]\n",
        "model = trainDecaptcha3(train_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjKFIEx0qEzp"
      },
      "outputs": [],
      "source": [
        "import time as tm\n",
        "num_test = 2000\n",
        "filepaths = [ \"/content/drive/MyDrive/Colab/train/%d.png\" % i for i in range(num_test ) ]\n",
        "file = open( \"/content/drive/MyDrive/Colab/train/labels.txt\", \"r\" )\n",
        "gold_output = file.read().splitlines()\n",
        "file.close()\n",
        "\n",
        "# Get recommendations from predict.py and time the thing\n",
        "tic = tm.perf_counter()\n",
        "output = decaptcha3( filepaths )\n",
        "toc = tm.perf_counter()\n",
        "\n",
        "parity_match = np.array( [ 1 if x.strip().upper() == y.strip().upper() else 0 for ( x, y ) in zip ( output, gold_output ) ] ).sum()\n",
        "\n",
        "print( f\"Time taken per image is {(toc - tic) / num_test} seconds\" )\n",
        "print( f\"Parity match score is {parity_match / num_test}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpmMT0ueEUr2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}